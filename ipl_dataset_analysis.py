# -*- coding: utf-8 -*-
"""IPL Dataset Analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Si-ksVBhQfif0UDTvAYmhU8Jh8NIbpVf

Importing Pandas to a load the datasets
"""

import pandas as pd
import numpy as np

"""Importing both the datasets i.e. matches.csv and deliveries.csv"""

matches_data = pd.read_csv('/content/drive/MyDrive/Datasets for DA/IPL datasets/matches.csv')
deliveries_data = pd.read_csv('/content/drive/MyDrive/Datasets for DA/IPL datasets/deliveries.csv')

"""Lets look at the datasets"""

matches_data.head()

deliveries_data.head()

matches_data.info()

deliveries_data.info()

"""##Cleaning Of Data

**Cleaning data for matches_data**

Handling Missing values for matches_data

First check percentage of missing data.
"""

missing_count = matches_data.isnull().sum()
total_cells = np.prod(matches_data.shape)
total_missing_count = missing_count.sum()

percentage_missing_value = (total_missing_count/total_cells)*100
percentage_missing_value

"""So here 5% data is missing, now as 5% is not that significant but it depends on the column also. If those columns which are important for our analysis then we should handle the missing values.

Lets see the total count of missing values for each column
"""

missing_count

"""Here city column has 51 missing values. Now Lets look at the broad picture.
First lets look at those record with missing value for city column.
"""

missing_city_matches = matches_data[matches_data["city"].isnull()]
missing_city_matches

"""So looking at the records we can see that only city are NaN but the Venue is giving. So based on the venue column we can provide city(if possible). Here only two venues are there that is "Sharjah Cricket Stadium" and "Dubai International Cricket Stadium" and both are out of India. So we can fill "Unknown" value instead NaN."""

matches_data.loc[:,"city"] = matches_data["city"].fillna("Unknown")

matches_data["city"].value_counts()

"""Here we can see all NaN values are replaced by "Unknown" and count is also 51.

Lets move to the next missing value column
"""

missing_count = matches_data.isnull().sum()
missing_count

"""Lets handle player_of_match column. Lets see the broad picture, and then do the needed."""

missing_player_of_match = matches_data[matches_data["player_of_match"].isnull()]
missing_player_of_match

"""Now here are the two possibilities of missing player_of_match. First can be that value is not recorded and second one can be that no one was awarded as the player of the match.
By looking at the other columns we can say that both winner and result column are NaN and no result value respectively. So there might be chances that these matches are the abandoned matches.
So just replace them with "no award" string.
"""

matches_data.loc[:,"player_of_match"] = matches_data["player_of_match"].fillna("no reward")

missing_count = matches_data.isnull().sum()
missing_count

"""Lets look at the winner column also."""

missing_winner = matches_data[matches_data["winner"].isnull()]
missing_winner

"""Again the same thing. But by looking at the the data we can just drop these rows. Tha can be better as they are abandoned matches."""

matches_data.dropna(subset = ["winner"], inplace = True)
missing_count = matches_data.isnull().sum()
missing_count

"""Now just result_margin column have 14 missing values and method column have 1069 values.
So we will just replace NaN values of result_margin caolumn with 0, as it is likely be the cases of Super Over or abandoned matches.
And for method column, we will just drop that column because it of not any use for our objectives.
"""

matches_data.loc[:,"result_margin"] = matches_data["result_margin"].fillna(0)

matches_data.drop(columns = ["method"], inplace = True)

"""Now lets see our final output for handling mising values."""

missing_count = matches_data.isnull().sum()
total_cells = np.prod(matches_data.shape)
total_missing_count = missing_count.sum()

percentage_missing_value = (total_missing_count/total_cells)*100
percentage_missing_value

"""As we can see that before it is 5% and now it is 0%.

At this point we have handled the missing value.
Now we will check if there is any duplicate values or not. If yes then we will remove them so that our data will be consistent.
"""

matches_data.duplicated().sum()

"""No duplicate values are present.

Lets check if we have unique teams or not.
"""

matches_data['team1'].unique()

"""Now here we can see data inconsistency that is, 'Royal Challengers Bangalore' and 'Royal Challengers Bengaluru' are treated different. Which is not acceptable.
More of these teams are 'Kings XI Punjab' & 'Punjab Kings', 'Delhi Daredevils' & 'Delhi Capitals', 'Deccan Chargers' & 'Sunrisers Hyderabad','Rising Pune Supergiants' & 'Rising Pune Supergiant'.

Lets replace these teams with the current team names.
"""

matches_data['team2'].unique()

"""Same for team2 also.
So replace them for both the teams and also for winner.
"""

team_name_replace = {
    "Royal Challengers Bangalore" : "Royal Challengers Bengaluru",
    "Kings XI Punjab" : "Punjab Kings",
    "Delhi Daredevils" : "Delhi Capitals",
    "Deccan Chargers" :  "Sunrisers Hyderabad",
    "Rising Pune Supergiant" : "Rising Pune Supergiants"
}

matches_data.replace({"team1": team_name_replace, "team2":team_name_replace, "winner": team_name_replace, "toss_winner": team_name_replace}, inplace = True)

"""Lets check if they are replaced or not."""

matches_data['team1'].unique()

matches_data['team2'].unique()

matches_data['winner'].unique()

matches_data['toss_winner'].unique()

"""Lets check for other columns also like Venue and city."""

matches_data['venue'].unique()

"""Here also inconsistency is present like "M Chinnaswamy Stadium" vs. "M.Chinnaswamy Stadium, Bengaluru". Some of the stadium has city menstioned also. Then some of the venue also has short forms.
So lets replace them. (Here you can take help of google to check the venue names)
"""

venue_name_replace = {
    "M Chinnaswamy Stadium": "M. Chinnaswamy Stadium",
    "M.Chinnaswamy Stadium": "M. Chinnaswamy Stadium",
    "M Chinnaswamy Stadium, Bengaluru": "M. Chinnaswamy Stadium",

    "Punjab Cricket Association IS Bindra Stadium, Mohali": "Punjab Cricket Association IS Bindra Stadium",
    "Punjab Cricket Association IS Bindra Stadium, Mohali, Chandigarh": "Punjab Cricket Association IS Bindra Stadium",

    "Feroz Shah Kotla": "Arun Jaitley Stadium",
    "Arun Jaitley Stadium, Delhi": "Arun Jaitley Stadium",

    "MA Chidambaram Stadium, Chepauk": "MA Chidambaram Stadium",
    "MA Chidambaram Stadium, Chepauk, Chennai": "MA Chidambaram Stadium",

    "Rajiv Gandhi International Stadium, Uppal": "Rajiv Gandhi International Stadium",
    "Rajiv Gandhi International Stadium, Uppal, Hyderabad": "Rajiv Gandhi International Stadium",

    "Dr DY Patil Sports Academy, Mumbai": "Dr DY Patil Sports Academy",

    "Wankhede Stadium, Mumbai": "Wankhede Stadium",

    "Eden Gardens, Kolkata": "Eden Gardens",

    "Sawai Mansingh Stadium, Jaipur": "Sawai Mansingh Stadium",

    "Himachal Pradesh Cricket Association Stadium, Dharamsala": "Himachal Pradesh Cricket Association Stadium",

    "Maharashtra Cricket Association Stadium, Pune": "Maharashtra Cricket Association Stadium",

    "Narendra Modi Stadium, Ahmedabad": "Narendra Modi Stadium",

    "Zayed Cricket Stadium, Abu Dhabi": "Sheikh Zayed Stadium",

    "Dr. Y.S. Rajasekhara Reddy ACA-VDCA Cricket Stadium, Visakhapatnam": "Dr. Y.S. Rajasekhara Reddy ACA-VDCA Cricket Stadium"
}

matches_data.replace({"venue": venue_name_replace}, inplace = True)

matches_data['venue'].unique()

"""Now for city column."""

matches_data['city'].unique()

city_replace = {
    "Bangalore": "Bengaluru",
    "Chandigarh": "Mohali",
    "Navi Mumbai": "Mumbai"
}

matches_data.replace({"city": city_replace}, inplace = True)

matches_data['city'].unique()

matches_data['city'].value_counts()

"""Here we notice that there are 51 unknown cities. This is the same number we handled during handling missing values, right?
But from above venues we can now tell that we had figured out the cities.
So lets replace them by there respective cities by mapping them.
"""

venue_city_map = {
    "M. Chinnaswamy Stadium": "Bengaluru",
    "Wankhede Stadium": "Mumbai",
    "Eden Gardens": "Kolkata",
    "Arun Jaitley Stadium": "Delhi",
    "MA Chidambaram Stadium": "Chennai",
    "Sawai Mansingh Stadium": "Jaipur",
    "Rajiv Gandhi International Stadium": "Hyderabad",
    "Punjab Cricket Association IS Bindra Stadium": "Mohali",
    "Dr DY Patil Sports Academy": "Mumbai",
    "Narendra Modi Stadium": "Ahmedabad",
    "Himachal Pradesh Cricket Association Stadium": "Dharamsala",
    "Maharashtra Cricket Association Stadium": "Pune",
    "Shaheed Veer Narayan Singh International Stadium": "Raipur",
    "JSCA International Stadium Complex": "Ranchi",
    "Barsapara Cricket Stadium": "Guwahati",
    "Green Park": "Kanpur",
    "Bharat Ratna Shri Atal Bihari Vajpayee Ekana Cricket Stadium": "Lucknow",
    "Sharjah Cricket Stadium": "Sharjah",
    "Dubai International Cricket Stadium": "Dubai",
    "Sheikh Zayed Stadium": "Abu Dhabi",
}


matches_data["city"] = matches_data.apply(lambda row: venue_city_map.get(row["venue"], row["city"]), axis=1)

"""Now see if we still have 'Unknown' value in city column or not."""

matches_data['city'].unique()

"""We are almost there now.

Now we will parsed the date column if needed.
For that we will check dtype of date column.
"""

matches_data['date'].dtype

"""Here 'O' means object type but we needed it in datetime dtype. So lets parsed the date column."""

matches_data.head()

"""From above 'date' column we can see that dates are in yyyy-mm-dd format, so we will parsed them in this format only.
Lets do it.
"""

matches_data["date"] = pd.to_datetime(matches_data["date"])

matches_data['date'].dtype

"""Now our 'date' column is converted into datetime dtype.

Here we had cleaned our dataset for matches_data now lets look for deliveries_data.
We will do the same, or extra if needed.

**Cleaning data for deliveries_data**
"""

deliveries_data.head()

"""Lets handle missing values."""

deliveries_data.isnull().sum()

"""Here we have {extras_type	246795} values means that no extra run was given so we can fill them with 'No Extra'.
Then for {player_dismissed	247970} values means no player was out on that ball, so we can fill them with 'Not Out'.
Then for {dismissal_kind	247970} values means no dimissal happened, so lets fill them by 'Not Out' again.
And for the {fielder	251566} means no fielder was involved, either the no dismissal happened or the ball hits the stump. So lets fill them with 'No Fielder'.

But we will not replace it beacause we want to analyse this data. This is useful if we want to filter only the rows where a player was actually dismissed, and all.

If we want dataset for readibility then we should replace with those strings but for analysis we should keep NaN values as it is.

Now lets ensure there is no duplicate values records exist.
So removing the duplicates.
"""

deliveries_data.drop_duplicates(inplace = True)

"""Now lets standarize the Team names for columns batting_team	&
bowling_team. (Do the same as we had done in matches_data)
"""

deliveries_data['batting_team'].unique()

deliveries_data['bowling_team'].unique()

"""Some of the teams are renamed or some of the teams have inconsistency in spelling. So lets fix this."""

deliveries_team_name_replace = {
    "Kings XI Punjab": "Punjab Kings",
    "Delhi Daredevils": "Delhi Capitals",
    "Rising Pune Supergiants": "Rising Pune Supergiant",
    "Royal Challengers Bangalore": "Royal Challengers Bengaluru",
    "Deccan Chargers": "Sunrisers Hyderabad"
}

deliveries_data.replace({"batting_team": deliveries_team_name_replace, "bowling_team": deliveries_team_name_replace}, inplace=True)

deliveries_data['batting_team'].unique()
deliveries_data['bowling_team'].unique()

"""Lets check datatypes for all the columns."""

deliveries_data.dtypes

#converting is_wicket to bool dtype

deliveries_data['is_wicket'].astype(bool)

"""Lets do the final check for both the datasets."""

matches_data.info()

matches_data.head()

deliveries_data.info()

deliveries_data.head()

"""Now all the cleaning is done. Lets move to next step that is:

##Exploratory Data Ananlysis (EDA)

###Understanding the data.

First we will understand the data and find the summary of both the datasets.
"""

#To see basic structure
matches_data.head()

matches_data.info()

matches_data.shape

"""So for matches_data dataset we have 19 columns and 1090 records. To see how data is stored we will look at the .head() part.

Now for deliveries_data.
"""

deliveries_data.head()

deliveries_data.info()

deliveries_data.shape

"""In deliveries_data dataset we can see that there are 17 columns and 260920 records.

Now lets check duplicated value if any, although we had handled them in cleaning phase but lets crosscheck it.
"""

matches_data.duplicated().sum()

deliveries_data.duplicated().sum()

"""Great! we dont have any duplicated value.
Now lets see the statistical summary of the data i.e. mean, mediun, mode etc for each and every column and observe them for better understanding the dataset.
"""

matches_data.describe()

deliveries_data.describe()

"""Ignore the non-numerical data, but it will help us to see statistical information about runs, over etc.

And now we will see unique values. It will help us to see how many unique team, player, stadium, season exists.
"""

matches_data.nunique()

deliveries_data.nunique()

"""Lets count seasons of the IPL. It will halp us to see how many matches were played in each season or year."""

matches_data['season'].value_counts().sort_index()

"""The main purpose of the above processes are to understand how the data is structured and spot any issues. As there is no problem with the data so lets move to the next process i.e. univariate analysis.

###Univariate Analysis (One column at a time)

Now we will analyse individual features or column to understand their distribution and characteristics.

**Lets see which has won the most IPL titles.**
"""

title_win = matches_data.drop_duplicates(subset = ["season"], keep = 'last')['winner'].value_counts()

import matplotlib.pyplot as plt

plt.figure(figsize=(10,5))
title_win.plot(kind = "bar", color = "skyblue", edgecolor = "black")
plt.title("Most IPL titles won by Teams", fontsize = 14)
plt.xlabel("Teams", fontsize = 12)
plt.ylabel("Number of Titles", fontsize = 12)
plt.xticks(rotation = 45)
plt.show()

"""From above chart we can easily see that Chennai Super Kings and Mumbai indians both has won most titles i.e. 5.

**Who is the Top Run-Scorer in IPL history?**
"""

top_scorers = deliveries_data.groupby("batter")["batsman_runs"].sum().sort_values(ascending=False).head(10)

plt.figure(figsize=(10,5))
top_scorers.plot(kind="bar", color="orange", edgecolor="black")
plt.title("Top 10 Run Scorers in IPL", fontsize=14)
plt.xlabel("Batsman", fontsize=12)
plt.ylabel("Total Runs", fontsize=12)
plt.xticks(rotation=45)
plt.show()

"""From above chart we can see that V Kohli is a Top Run-Scorer in IPL history i.e. about 8000 total runs.

###Bivariate & Multivariate Analysis (Finding Relationship)

***Does Winning the Toss Increase the Chances of Winning?***
"""

toss_win_match_win = matches_data[matches_data['toss_winner'] == matches_data['winner']].shape[0]

total_matches = matches_data['winner'].shape[0]

toss_win_percentage = (toss_win_match_win/total_matches)*100
toss_loss_percentage = 100 - toss_win_percentage

print(f'Teams that won the toss and also won the match is {toss_win_percentage:.2f}% of times.')

# Define labels and data
labels = ["Toss Winner Also Won Match", "Toss Winner Lost Match"]
sizes = [toss_win_percentage, toss_loss_percentage]
colors = ["green", "red"]  # Green for winning, Red for losing
explode = (0.1, 0)  # Slightly separate the Toss Winner segment for emphasis

# Create Pie Chart
plt.figure(figsize=(6,6))
plt.pie(sizes, labels=labels, autopct="%1.1f%%", colors=colors, startangle=90, explode=explode)
plt.title("Toss Impact: Does Winning the Toss Help Win the Match?", fontsize=14)
plt.show()

"""From above result we can say that winning toss does not impact winning possibility. Though there are certain advantages of winnig toss due to some factors like pitch, due etc.

***Who has taken the most wickets in IPL history?***
"""

#filtering only wicket taking deliveries
wicket_deliveries = deliveries_data[deliveries_data['is_wicket'] == 1]

#counting wikets for each bowler
wickets_per_bowler = wicket_deliveries.groupby('bowler')['is_wicket'].count()

#sorting them in descending order
sorted_wickets = wickets_per_bowler.sort_values(ascending = False)

#taking only top 10
top_10_bowler = sorted_wickets.head(10)

print(top_10_bowler)

"""Here we can tell that YS Chahal is the bowler with most wickets.

If we want to visualize it then we can do this:
"""

plt.figure(figsize=(10,5))

top_10_bowler.plot(kind="bar", color="purple", edgecolor="black")

plt.title("Top 10 Wicket-Takers in IPL", fontsize=14)
plt.xlabel("Bowler", fontsize=12)
plt.ylabel("Total Wickets", fontsize=12)
plt.xticks(rotation=45)

plt.show()

"""***Which stadium favours which team?***"""

venue_wins = matches_data.groupby(['venue','winner']).size().reset_index(name = 'wins')
venue_best_teams = venue_wins.loc[venue_wins.groupby("venue")["wins"].idxmax()]

venue_best_teams

import seaborn as sns

# Sort values for better visualization
venue_best_teams = venue_best_teams.sort_values(by="wins", ascending=False)

# Plot
plt.figure(figsize=(12, 6))
sns.barplot(y=venue_best_teams["venue"], x=venue_best_teams["wins"], hue=venue_best_teams["winner"], dodge=False, palette="viridis")

# Labels & Title
plt.xlabel("Total Wins at Venue", fontsize=12)
plt.ylabel("Venue", fontsize=12)
plt.title("Best Team at Each IPL Venue üèüÔ∏è", fontsize=14)
plt.legend(title="Winning Team", bbox_to_anchor=(1.05, 1), loc="upper left")
plt.grid(axis="x", linestyle="--", alpha=0.7)

# Show Plot
plt.show()

"""***Run Patterns:Batting first vs Chasing?***

Lets make a pie chart to understand quickly.
"""

batting_first_wins = matches_data[matches_data['team1'] == matches_data['winner']].shape[0]
chasing_wins = matches_data.shape[0] - batting_first_wins

#making pie chart
labels = ["Batting First Wins", "Chasing Wins"]
sizes = [batting_first_wins, chasing_wins]
colors = ["pink", "skyblue"]

plt.figure(figsize=(6,6))
plt.pie(sizes, labels=labels, autopct="%1.1f%%", colors=colors, startangle=90)
plt.title("Winning Trends: Batting First vs Chasing", fontsize=14)
plt.show()

"""***Who had hit the most sixes in IPL history***"""

sixes_only = deliveries_data[deliveries_data['batsman_runs'] == 6]
sixes_count = sixes_only.groupby('batter')["batsman_runs"].count()

sorted_six = sixes_count.sort_values(ascending = False)
top_10_six_hitters = sorted_six.head(10)

top_10_six_hitters

#visualize it

plt.figure(figsize=(10,5))
top_10_six_hitters.plot(kind="bar", color="blue", edgecolor="black")
plt.title("Top 10 Six Hitters in IPL", fontsize=14)
plt.xlabel("Batsman", fontsize=12)
plt.ylabel("Total Sixes", fontsize=12)
plt.xticks(rotation=45)
plt.show()

"""***Which Bowler Has the Best Economy Rate in IPL?***"""

bowlers_run = deliveries_data.groupby('bowler')['total_runs'].sum()
bowlers_ball = deliveries_data.groupby('bowler')['ball'].count()
bowlers_overs = bowlers_ball/6

#calculatin economy rate (economy = total runs given/ total overs bowled)
economy = (bowlers_run/bowlers_overs).sort_values(ascending = True)

top_economy_bowlers = economy.head(10)

top_economy_bowlers

plt.figure(figsize=(10,5))
top_economy_bowlers.plot(kind="bar", color="yellow", edgecolor="black")
plt.title("Top 10 Bowlers in IPL", fontsize=14)
plt.xlabel("Bowler", fontsize=12)
plt.ylabel("Total Wickets", fontsize=12)
plt.xticks(rotation=45)
plt.show()

"""***MVPs (Most Valuable Players)***"""

top_mvps = matches_data["player_of_match"].value_counts().head(10)
top_mvps

#visualize it
plt.figure(figsize=(10,5))
top_mvps.plot(kind="bar", color="red", edgecolor="black")
plt.title("Top 10 MVPs in IPL", fontsize=14)
plt.xlabel("Player", fontsize=12)
plt.ylabel("Total Player of the Match Awards", fontsize=12)
plt.xticks(rotation=45)
plt.show()

"""***Matches played per season***"""

import seaborn as sns

matches_per_season = matches_data["season"].value_counts().sort_index()

plt.figure(figsize=(10,5))
sns.barplot(x=matches_per_season.index, y=matches_per_season.values, palette="magma")
plt.title("Total Matches Played Per Season", fontsize=14)
plt.xlabel("Season", fontsize=12)
plt.ylabel("Number of Matches", fontsize=12)
plt.xticks(rotation=45)
plt.show()

"""Lets see ***How do batsmen usually get out?***"""

wicket_types = deliveries_data["dismissal_kind"].value_counts()

plt.figure(figsize=(10,5))
sns.barplot(x=wicket_types.index, y=wicket_types.values, palette="coolwarm", edgecolor="black")
plt.title("Wicket Types in IPL", fontsize=14)
plt.xlabel("Wicket Type", fontsize=12)
plt.ylabel("Count", fontsize=12)
plt.xticks(rotation=45)
plt.show()

"""Lest see ***Runs per over***"""

runs_per_over = deliveries_data.groupby(["over"])["total_runs"].sum().reset_index()

plt.figure(figsize=(10,5))
sns.heatmap(runs_per_over.pivot_table(values="total_runs", index="over"), cmap="Reds", annot=True, fmt="g")
plt.title("Runs Scored per Over in IPL", fontsize=14)
plt.xlabel("Over Number", fontsize=12)
plt.ylabel("Total Runs", fontsize=12)
plt.show()

"""lets see ***Team wise total runs***"""

team_runs = deliveries_data.groupby("batting_team")["total_runs"].sum().sort_values(ascending=False)

plt.figure(figsize=(12,5))
sns.barplot(x=team_runs.index, y=team_runs.values, palette="coolwarm")
plt.title("Total Runs Scored by Teams in IPL", fontsize=14)
plt.xlabel("Teams", fontsize=12)
plt.ylabel("Total Runs", fontsize=12)
plt.xticks(rotation=90)
plt.show()

team_runs.head(10)